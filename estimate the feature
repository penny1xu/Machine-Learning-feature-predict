!pip install catboost
!pip install shap

import numpy as np
import pandas as pd
import xgboost as xgb
from xgboost import XGBClassifier 
import seaborn as sns
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from catboost import CatBoostClassifier
import math
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import shap
from sklearn.model_selection import cross_val_score


from pandas.core.arrays import string_
# Train_data
Train_Instance = pd.read_csv("/content/train.mv.txt", sep=" ", header=None, na_values='?')

X = Train_Instance.iloc[: , :-2]
Y = Train_Instance.iloc[: , -2]
X.info()


dataTypeSeries = X.dtypes
print('Data type of each column of Dataframe :')
print(dataTypeSeries)


Final = pd.read_csv("/content/final-mv-noclass.txt", sep=" ", header=None, na_values='?')
Final = Final.applymap(str)
Final_X = Final.iloc[: , :-2]
Final_Y = Final.iloc[: , -2]
Final_X

SEED = 42
X_train.info()

cat_features_names = X.columns[122:] # here we specify names of categorical features
cat_features = [X.columns.get_loc(col) for col in cat_features_names]
print(cat_features)

all_features = list(range(X.shape[1]))
print(all_features)

import sys
from catboost import Pool

cat_features_names = X.columns[122:] 
cat_features = [X.columns.get_loc(col) for col in cat_features_names]
print(cat_features)

pool = Pool(X_valid, y_valid, cat_features=cat_features)


params = {'loss_function':'Logloss',
          'eval_metric':'AUC',
          'verbose': 200,
          'random_seed': SEED,
          'max_depth': 8,
          'early_stopping_rounds': 400,
          'cat_features':cat_features
         }

cbc_9 = CatBoostClassifier(**params)

all_features = list(range(X.shape[1]))
cbc_10 = cbc_9.select_features(
                X_train,
                y=y_train,
                eval_set=pool,
                features_for_select=all_features,
                num_features_to_select=110,
                algorithm="RecursiveByShapValues",
                steps=2,
                shap_calc_type="Approximate",
                train_final_model=True,
                logging_level="Verbose",
                plot=True,
                log_cout=sys.stdout,
                log_cerr=sys.stderr)
                
pred_class = cbc_9.predict(X_valid)

y_valid.head(30)

preds_class = cbc_9.predict(X_valid)
preds_class[:30]

y_valid.head(30)


# Here is the place I generated the Prediction file
from numpy import savetxt

FinalPred_class = cbc_9.predict(Final_X)

results = list(map(int, FinalPred_class))

savetxt('Prediction3.txt', results, delimiter=',', fmt="%d")
pred_class[:30]
